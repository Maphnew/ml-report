# 머신러닝 리포트 - 분류1
> 로지스틱 회귀(이진 분류, 2개의 카테고리)
---
## 목차
1. 시나리오
2. 목표
3. 프로세스   
    3-1. 흐름도   
    3-2. Load Data   
    3-3. Pre-Processing   
    3-4. Modeling   
    3-5. Evaluation   
4. 결론
---
### 1. 시나리오
- 파형의 특성에 따라 라벨을 적용할 수 있을 때 머신러닝 모델을 이용하여 분류를 할 수 있다. 
- 예제 데이터는 엘리베이터 UP/DOWN 라벨이 있는 데이터를 이용하여 분류를 실행 한다.

### 2. 목표
- 기간과 아이템을 선택하고 데이터를 파형별로 구분하고 통계값을 계산한다.
- 모델에 적용하기 위해 원하는 형태로 전처리 한다.
- 정규 분포 형태의 표준스케일링 적용 후 학습 / 테스트 데이터로 나눈다.
- 로지스틱 회귀 모델로 학습 및 예측을 수행한다.
- 정확도와 ROC-AUC 값 구한다.
- 하이퍼파라미터 최적화를 수행한다.

### 3. 프로세스
#### 3-1. 흐름도
![Process Image](./process.png)
#### 3-2. Load Data
##### - Select Period & Item
1. Period: 2020-05-01 ~ 2020-05-14
2. Item: ElevatorMain MaxCurrent
##### - Indexing & Extraction Statistics
1. Indexing
- EndCount: 2초(파형의 시작과 종료를 구분하기 위한 시간)

2. Extraction Statistics(17개)
- max
- average
- area 
- median
- var
- std
- skew
- kurtosis
- Q1
- Q3 
- iqr 
- percentile10 
- percentile40 
- percentile60
- percentile90
- trim_mean10
- trim_mean20

> Index / Statistics   
![Index_Table](./index_table.png)


##### - Labeling
- 저장된 UP/DOWN 신호를 이용하여 라벨링

> Label
![Label_Table](./label_table.png)

#### 3-3. Pre-Process
##### - Pre-Processing
- 모델에 적용하기 위해 원하는 형태로 전처리

> Features
```python
# DATA
[['14.29' '3.56' '519.52' ... '7.8' '2.83' '2.68']
 ['21.3' '8.57' '1268.47' ... '11.9' '8.28' '8.9']
 ['13.87' '3.66' '406.17' ... '8.51' '2.87' '2.42']
 ...
 ['17.47' '5.56' '817.68' ... '9.56' '4.98' '5.14']
 ['13.93' '3.27' '474.83' ... '7.41' '2.51' '2.28']
 ['19.91' '7.04' '1035.12' ... '10.65' '6.6' '7.02']]

 # LENGTH
2963

# TYPE
<class 'numpy.ndarray'>
```
> Target
```python
# DATA
[1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 
...
1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0]

# LENGTH
2963

# TYPE
<class 'list'>
```

##### - Scaling(평균 0, 분산 1로 데이터 분포도 변환)
- 정규 분포 형태의 표준 스케일링 적용

> Features
```python
# DATA
[[-0.68371451 -1.00025274 -0.44138566 ... -1.37114    -0.94833775
  -0.88346797]
 [-1.15891996 -1.18069918 -0.62345674 ... -1.47398456 -1.10423386
  -1.03055082]
 [ 1.04456246  0.97206883  1.09280422 ...  0.21753789  1.01367185
   1.06281441]
 ...
 [-0.76008682 -0.87435987 -0.88429488 ... -0.10452798 -0.92552368
  -0.94845807]
 [-0.99486094 -1.12614561 -0.5699796  ... -1.48751674 -1.07761745
  -1.00318657]
 [-1.10517649 -1.13453846 -0.70996628 ... -1.28453405 -1.08902448
  -1.02028923]]
```

#### 3-4. Modeling
##### - Split
- Train 데이터와 Test 데이터를 7:3으로 분할 구성
- 재현성을 위하여 random state(seed)는 0으로 입력한다.
- 분할된 변수: X_train, X_test, y_train, y_test
```python
# X_train
[[-0.68371451 -1.00025274 -0.44138566 ... -1.37114    -0.94833775
  -0.88346797]
 [-1.15891996 -1.18069918 -0.62345674 ... -1.47398456 -1.10423386
  -1.03055082]
 [ 1.04456246  0.97206883  1.09280422 ...  0.21753789  1.01367185
   1.06281441]
 ...
 [-0.99768954 -1.05060989 -0.6584043  ... -1.22499246 -1.02818697
  -0.95871966]
 [-1.1164909  -1.07998489 -0.8433563  ... -0.80549489 -1.07761745
  -1.02370976]
 [ 0.92010389  0.78322953 -0.35065294 ...  1.53015932  0.64864681
   0.59078107]]

# X_test
[[ 0.84090298  0.90492596  1.02515163 ...  0.17423492  0.95663669
   0.99440378]
 [ 1.29913681  1.47564029  1.52888762 ...  0.60997111  1.54219769
   1.58615572]
 [ 1.2934796   1.38751528  0.97930239 ...  0.63432903  1.39390627
   1.48696031]
 ...
 [-0.76008682 -0.87435987 -0.88429488 ... -0.10452798 -0.92552368
  -0.94845807]
 [-0.99486094 -1.12614561 -0.5699796  ... -1.48751674 -1.07761745
  -1.00318657]
 [-1.10517649 -1.13453846 -0.70996628 ... -1.28453405 -1.08902448
  -1.02028923]]

# y_train
[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 
...
0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0]

# y_test
[0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 
...
0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1]
```

##### - Train / Test
- 로지스틱 회귀로 분류 수행
> Train   
```python
lr_clf = LogisticRegression()
lr_clf.fit(X_train, y_train)
```

> Test   
```python
lr_preds = lr_clf.predict(X_test)
```

#### 3-5. Evaluation
##### - Evaluation

> accuracy & roc_auc
```python
# 정확도와 roc_auc 측정
print('accuracy: {:0.3f}'.format(accuracy_score(y_test, lr_preds)))
print('roc_auc: {:0.3f}'.format(roc_auc_score(y_test, lr_preds)))
```
```python
accuracy: 0.971
roc_auc: 0.970
```

##### - 하이퍼파라미터 최적화
- 규제(Regularization)와 규제 강도(alpha)
- C = 1 / alpha
- C값이 작을수록 규제 강도가 큼
- 하이퍼 파라미터 최적화

> Regularization & alpha
```python
from sklearn.model_selection import GridSearchCV

params = {'penalty' : ['l2','l1'],
         'C': [0.01, 0.1, 1, 1, 5, 10]}

grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy', cv=3)
grid_clf.fit(data_scaled, list_label)
print('최적 하이퍼 파라미터:{0}, 최적 평균 정확도:{1:.3f}'.format(grid_clf.best_params_, grid_clf.best_score_))
```
```python
최적 하이퍼 파라미터:{'C': 0.1, 'penalty': 'l1'}, 최적 평균 정확도:0.972
```
### 4. 결론
- 엘리베이터 데이터의 통계값을 이용한 분류 예측은 약 97%의 정확도로 높은 편이다.
- 로지스틱 회귀를 이용한 이진 분류 예측 성능이 뛰어나다.